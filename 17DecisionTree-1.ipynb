{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1. Describe the decision tree classifier algorithm and how it works to make predictions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Ans: A Decision Tree Classifier is a supervised learning algorithm used for classification tasks. It splits the data recursively based on feature values to form a tree structure. Each internal node represents a decision rule, each branch represents an outcome of the rule, and each leaf node represents a class label.\n",
    "\n",
    "1. Building the Tree \n",
    "    - Start at the Root: using Information guess we select the start of the split.\n",
    "    - Choosing the best split: A splitting criterion is used to measure the \"purity\" or \"separation\" achieved by a split:              \n",
    "        - Gini Impurity\n",
    "        - Entropy/Information Gain\n",
    "    The feature and threshold that maximize the improvement(Reduce impurity the most ) are selected\n",
    "    - Spliting the Data: \n",
    "        - The dataset is split into subsets based on the chosen feature and threshold.\n",
    "        - Each subset forms a branch of the tree.\n",
    "    - Stopping Criteria:\n",
    "        - The recursive splitting process stops when:\n",
    "        - All samples in a node belong to the same class.\n",
    "        - A pre-defined maximum tree depth is reached.\n",
    "        - A minimum number of samples per node is specified.\n",
    "        - Further splits do not improve the separation significantly.\n",
    "    - Assigning Class Labels\n",
    "\n",
    "2. Making Predictions(Inference Phase):\n",
    "    - Start at the Root\n",
    "    - Follow Decision Rules\n",
    "    - Traverse Down the Tree\n",
    "    - Reach a Leaf Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Q2. Provide a step-by-step explanation of the mathematical intuition behind decision tree classification.**\n",
    "\n",
    "Ans: Mathematical Intution Behind Decision Tree Classification\n",
    "1. Data Splitting:\n",
    "    - At each node, the data is split based on feature thresholds\n",
    "    - The goal is to create subsets that are as \"pure\" as possible.\n",
    "\n",
    "2. Impurity Measurement:\n",
    "    - A metric is used to measure how well a split separates the classes:\n",
    "        - Gini Impurity\n",
    "        - Entropy\n",
    "        - Lower values indicate purer nodes.\n",
    "\n",
    "3. Information Gain:\n",
    "    - The improvement in purity is measured as Information Gain:\n",
    "    - The split with hiighest information gain is chosen\n",
    "\n",
    "4. Recursive Splitting:\n",
    "    - The process is repeated for each child node, dividing the data further until a stopping criterion is met\n",
    "\n",
    "5. Class Assignment:\n",
    "    - At leaf nodes, the class label is assigned based on the majority class of the samples in that node.\n",
    "\n",
    "6. Prediction:\n",
    "    - To classify a new data point, traverse the tree by applying decision rules at each node until reaching a leaf, where the predicted class is label of the leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Q3. Explain how a decision tree classifier can be used to solve a binary classification problem.**\n",
    "\n",
    "Ans: \n",
    "1. Training the Tree:\n",
    "    - Start at the root with the entire dataset.\n",
    "    - Evaluate features to find the best split using criteria like Gini Impurity or Information Gain.\n",
    "    - Split the data into subsets based on the chosen feature and threshold(e.g., Feature X<= 5).\n",
    "    - Repeat this process recursively until a stopping criterion is met(e.g., all samples in a node belong to the same class, or a maximum depth is reached).\n",
    "\n",
    "2. Prediction:\n",
    "    - For a new data point, start at the root node.\n",
    "    - Apply decision rules(e.g., Feature X<=5) at each node.\n",
    "    - Traverse the tree along the branches corresponding to the feature values.\n",
    "    - Assign the class label of the leaf node where the traversal ends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Q4. Discuss the geometric intuition behind decision tree classification and how it can be used to make\n",
    "predictions.**\n",
    "\n",
    "Ans: Geometric Intution of Decision Tree Classification\n",
    "- A decision tree partitions the feature space into rectangular regions by splitting on individual feature thresholds(e.g., Feature x <= 5).\n",
    "- Each split creates axis-aligned boundaries that separate the classes.\n",
    "\n",
    "Making Predictions\n",
    "1. A new data point is located in the feature space.\n",
    "2. Follow the splits(boundaries) to identify the rectangular region the point belongs to.\n",
    "3. Assign the class label of that region (based on the majority class within it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Q5. Define the confusion matrix and describe how it can be used to evaluate the performance of a\n",
    "classification model.**\n",
    "\n",
    "Ans:\n",
    "A confusion matrix is a table used to evaluate the performance of a classification model. It compares the actual(true) labels with the predicted labels, providing a breakdown of correct and incorrect predictions.\n",
    "\n",
    "How It Evaluates Performance\n",
    "- Accuracy: Proportion of correct predictions.\n",
    "- Precision: Proportion of positive predictions that are correct.\n",
    "- Recall(Sensitivity): Proportion of actual positives correctly identified.\n",
    "- F1-Score: Harmonic mean of precision and recall\n",
    "\n",
    "By analyzing these metrics, the confusion matrix helps assess a model's strengths and weaknesses in handling different types of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Q6. Provide an example of a confusion matrix and explain how precision, recall, and F1 score can be\n",
    "calculated from it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Types</th>\n",
       "      <th>Predicted Positive</th>\n",
       "      <th>Predicted Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actual Positive</td>\n",
       "      <td>50 (True Positive, TP)</td>\n",
       "      <td>10 (False Negative, FN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actual Negative</td>\n",
       "      <td>5 (False Positive, FP)</td>\n",
       "      <td>35 (True Negative, TN)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Types      Predicted Positive       Predicted Negative\n",
       "0  Actual Positive  50 (True Positive, TP)  10 (False Negative, FN)\n",
       "1  Actual Negative  5 (False Positive, FP)   35 (True Negative, TN)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({\"Types\":[\"Actual Positive\",\"Actual Negative\"]\n",
    ",\"Predicted Positive\":[\"50 (True Positive, TP)\",\"5 (False Positive, FP)\"],\n",
    "\"Predicted Negative\":[\"10 (False Negative, FN)\",\"35 (True Negative, TN)\"]}) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision: Measures the proportion of correctly predicted positives out of all positive predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision=50/(50+5)\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: Measures the proportion of actual positives coreectly identified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall=50/(50+10)\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-Score: Harmonic mean of precision and recall, balancing both metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8695652173913043"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1=2*((precision*recall)/(precision+recall))\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Q7. Discuss the importance of choosing an appropriate evaluation metric for a classification problem and\n",
    "explain how this can be done.**\n",
    "\n",
    "1. For Balanced Datasets: Use Accuracy.\n",
    "2. For Imbalanced Datasets:\n",
    "    - Precision: Prioritize minimizing false positives (e.g., spam detection).\n",
    "    - Recall: Focus on minimizing false negatives (e.g., disease diagnosis).\n",
    "    - F1-Score: Balance precision and recall.\n",
    "3. Custom Business Needs: Choose metrics like ROC-AUC, PR-AUC, or cost-sensitive approaches based on the problem's impact.\n",
    "\n",
    "Always align the metric with the problem's critical outcomes.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Q8. Provide an example of a classification problem where precision is the most important metric, and\n",
    "explain why.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spam classification problem as in that case our fp become more important and we need to reduce fp therefore our precision should be good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Q9. Provide an example of a classification problem where recall is the most important metric, and explain\n",
    "why.**\n",
    "\n",
    "Ans:Disease identification problem as in that case our fn become more important and we need to reduce fn therefore our recall should be good"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
